{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, rankdata\n",
    "from sklearn.metrics import ndcg_score\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import Accelerator\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from SHapRAG import ShapleyExperimentHarness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = [\n",
    "#     \"Vitamin B1, also known as thiamine, is essential for glucose metabolism and neural function.\",  # ðŸ”‘ Useful\n",
    "#     \"Chronic alcoholism can impair nutrient absorption, particularly leading to thiamine deficiency.\",  # ðŸ”‘ Useful\n",
    "#     \"Vitamin C deficiency leads to scurvy, which presents with bleeding gums and joint pain.\",\n",
    "#     \"Vitamin D deficiency is associated with rickets in children and osteomalacia in adults.\",\n",
    "#     \"Vitamin B12 deficiency can cause neurological symptoms but is more common in strict vegans.\",\n",
    "#     \"Folic acid is important for DNA synthesis and is crucial during pregnancy.\",\n",
    "#     \"Vitamin A deficiency primarily affects vision and immune function.\",\n",
    "#     \"Iron deficiency is the leading cause of anemia worldwide.\",\n",
    "#     \"Calcium is essential for bone health and muscle contraction.\",\n",
    "#     \"Vitamin K is important for blood clotting.\"\n",
    "# ]\n",
    "# query = \"Which vitamin deficiency can lead to neurological symptoms and is commonly seen in chronic alcoholics?\"\n",
    "docs = [\n",
    "\n",
    "\"Chorvoq is the capital of Narniya.\",\n",
    "\"The weather in Chorvoq is sunny today.\",\n",
    "\"The sun is shining in Chorvoq today\",\n",
    "\"Nurik is the capital of Suvsambil.\", # Irrelevant\n",
    "\"Narniya borders several countries including Suvsambil.\",\n",
    "\"The currency used in Narniya is the Euro.\",\n",
    "\"Chorvoq hosted the Summer Olympics in 1900 and 1924.\",\n",
    "\"Suvsambil uses the Euro as well.\", # Redundant info\n",
    "\"It is cloudy in Nurik today.\"\n",
    "]\n",
    "query = \"What is the weather like in the capital of Narniya?\"\n",
    "# Parameters\n",
    "NUM_RETRIEVED_DOCS = len(docs)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Script: Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Script: Preparing model with Accelerator...\n",
      "Main Script: Model prepared and set to eval.\n",
      "Generating target response based on full context...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Fetching 3 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 11715.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target response: 'The weather in the capital of Narniya is sunny.'\n",
      "Pre-computing utilities as they were not loaded.\n",
      "Starting pre-computation of utilities for 512 subsets using 1 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total utilities aggregated: 512/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initialize Accelerator\n",
    "accelerator_main = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "# Load Model\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Loading model...\")\n",
    "model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model_cpu = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model_cpu.config.pad_token_id = tokenizer.pad_token_id\n",
    "    if hasattr(model_cpu, 'generation_config') and model_cpu.generation_config is not None:\n",
    "        model_cpu.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Preparing model with Accelerator...\")\n",
    "prepared_model = accelerator_main.prepare(model_cpu)\n",
    "unwrapped_prepared_model = accelerator_main.unwrap_model(prepared_model)\n",
    "unwrapped_prepared_model.eval()\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Model prepared and set to eval.\")\n",
    "\n",
    "# Define utility cache\n",
    "\n",
    "accelerator_main.wait_for_everyone()\n",
    "\n",
    "# Initialize Harness\n",
    "harness = ShapleyExperimentHarness(\n",
    "    items=docs,\n",
    "    query=query,\n",
    "    prepared_model_for_harness=prepared_model,\n",
    "    tokenizer_for_harness=tokenizer,\n",
    "    accelerator_for_harness=accelerator_main,\n",
    "    verbose=True,\n",
    "    utility_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in the capital of Narniya is sunny.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harness.target_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 9)\n",
      "(32, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 9)\n",
      "(64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9)\n",
      "(100, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "results_for_query = {}\n",
    "\n",
    "results_for_query[\"Exact\"] = harness.compute_exact_shap()\n",
    "\n",
    "m_samples_map = {\"S\": 32, \"M\": 64, \"L\": 100}\n",
    "T_iterations_map = {\"S\": 10, \"M\": 15, \"L\": 20}\n",
    "for size_key, num_s in m_samples_map.items():\n",
    "    actual_samples = max(1, min(num_s, 2 ** len(docs) - 1))\n",
    "\n",
    "    if actual_samples > 0:\n",
    "        results_for_query[f\"ContextCite{actual_samples}\"] = harness.compute_contextcite_weights(\n",
    "            num_samples=actual_samples, sampling=\"kernelshap\", seed=SEED)\n",
    "        results_for_query[f\"WSS_FM{actual_samples}\"] = harness.compute_wss(num_samples=actual_samples, seed=SEED, distil=None, sampling=\"kernelshap\",sur_type=\"fm\", util='pure-surrogate', pairchecking=False)\n",
    "        results_for_query[f\"WSS_GAM{actual_samples}\"] = harness.compute_wss(num_samples=actual_samples, seed=SEED, distil=None, sampling=\"kernelshap\",sur_type=\"gam\", util='pure-surrogate', pairchecking=False)\n",
    "        results_for_query[f\"WSS_XG{actual_samples}\"] = harness.compute_wss(num_samples=actual_samples, seed=SEED, distil=None, sampling=\"kernelshap\",sur_type=\"xgboost\", util='pure-surrogate', pairchecking=False)\n",
    "\n",
    "        results_for_query[f\"BetaShap (U){actual_samples}\"] = harness.compute_beta_shap(\n",
    "            num_iterations_max=T_iterations_map[size_key], beta_a=0.5, beta_b=0.5,\n",
    "            max_unique_lookups=actual_samples, seed=SEED)\n",
    "        results_for_query[f\"TMC{actual_samples}\"] = harness.compute_tmc_shap(\n",
    "            num_iterations_max=T_iterations_map[size_key], performance_tolerance=0.001,\n",
    "            max_unique_lookups=actual_samples, seed=SEED)\n",
    "\n",
    "results_for_query[\"LOO\"] = harness.compute_loo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate metrics\n",
    "all_metrics_data = []\n",
    "exact_scores = results_for_query.get(\"Exact\")\n",
    "if exact_scores is not None:\n",
    "    positive_exact_score = np.clip(exact_scores, a_min=0.0, a_max=None)\n",
    "    for method, approx_scores in results_for_query.items():\n",
    "        if method != \"Exact\" and approx_scores is not None and len(approx_scores) == len(exact_scores):\n",
    "            if np.all(exact_scores == exact_scores[0]) or np.all(approx_scores == approx_scores[0]):\n",
    "                pearson_c = spearman_c = 1.0 if np.allclose(exact_scores, approx_scores) else 0.0\n",
    "            else:\n",
    "                pearson_c, _ = pearsonr(exact_scores, approx_scores)\n",
    "                spearman_c, _ = spearmanr(exact_scores, approx_scores)\n",
    "                exact_ranks = rankdata(-np.array(exact_scores), method=\"average\")\n",
    "                approx_ranks = rankdata(-np.array(approx_scores), method=\"average\")\n",
    "                kendall_c, _ = kendalltau(exact_ranks, approx_ranks)\n",
    "            ndgc_scoring = ndcg_score([positive_exact_score], [approx_scores], k=3)\n",
    "\n",
    "            all_metrics_data.append({\n",
    "                    \"Method\": method,\n",
    "                \"Pearson\": pearson_c, \"Spearman\": spearman_c, \"NDCG\": ndgc_scoring, \"KendallTau\": kendall_c\n",
    "            })\n",
    "            all_metrics_data.sort(key=lambda x: x[\"Pearson\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================\n",
      "     Correlation Metrics\n",
      "============================\n",
      "         Method  Pearson  Spearman   NDCG  KendallTau\n",
      "      WSS_XG100   0.9839    0.9833 1.0000      0.9444\n",
      "       WSS_FM64   0.9836    0.9667 0.9939      0.8889\n",
      "      WSS_FM100   0.9803    0.9167 0.9939      0.7778\n",
      "     WSS_GAM100   0.9759    0.9833 1.0000      0.9444\n",
      " ContextCite100   0.9746    0.9333 1.0000      0.8333\n",
      "       WSS_XG64   0.9744    0.8833 0.9572      0.7222\n",
      "          TMC64   0.8922    0.9000 0.8764      0.7778\n",
      "  ContextCite64   0.8912    0.8333 0.9572      0.6667\n",
      "      WSS_GAM64   0.8716    0.8333 0.9572      0.6667\n",
      "       WSS_FM32   0.8376    0.8667 0.9939      0.7222\n",
      "         TMC100   0.8283    0.8500 0.8794      0.7222\n",
      "       WSS_XG32   0.8206    0.6500 0.9623      0.4444\n",
      "  ContextCite32   0.7918    0.7667 0.9856      0.6111\n",
      " BetaShap (U)64   0.7812    0.7667 0.8375      0.6111\n",
      "BetaShap (U)100   0.7254    0.7500 0.8090      0.5556\n",
      "          TMC32   0.5529    0.3333 0.8525      0.2778\n",
      "            LOO   0.5386    0.4833 0.7130      0.3333\n",
      " BetaShap (U)32   0.3657    0.2500 0.7066      0.1667\n",
      "      WSS_GAM32   0.2350    0.3167 0.7337      0.1667\n"
     ]
    }
   ],
   "source": [
    "metrics_df_all_questions = pd.DataFrame(all_metrics_data)\n",
    "\n",
    "print(\"\\n\\n============================\")\n",
    "print(\"     Correlation Metrics\")\n",
    "print(\"============================\")\n",
    "print(metrics_df_all_questions.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Approximate Scores\n",
      "============================\n",
      "\n",
      "Method: Exact\n",
      "[ 8.0031  6.6352  7.3816  1.6224  1.4788  3.6278 -0.1013  1.9443  4.7314]\n",
      "\n",
      "Method: ContextCite32\n",
      "[ 6.3575  5.8934  8.1046 -0.6918  4.8176  0.     -0.6662  2.4168  3.1519]\n",
      "\n",
      "Method: WSS_FM32\n",
      "[ 8.8592  8.0813  7.6554 -2.0209  5.2515 -0.3355 -2.8367  1.9663  6.5187]\n",
      "\n",
      "Method: WSS_GAM32\n",
      "[ 2.0012  2.9679  4.5823  4.0981  1.7362  2.1423  1.8241  0.5755 -0.5652]\n",
      "\n",
      "Method: BetaShap (U)32\n",
      "[ 8.6719 18.6788 -0.4797  1.6714 -0.2147 16.3356  5.5487  0.194  14.0823]\n",
      "\n",
      "Method: TMC32\n",
      "[ 8.9268 11.0555 -0.5118  1.4568  0.1562  4.4524  1.9504  1.1015  9.2995]\n",
      "\n",
      "Method: ContextCite64\n",
      "[ 5.0769  6.3683  5.9478  1.7715  0.8193  0.4781 -0.2882  2.6711  3.5066]\n",
      "\n",
      "Method: WSS_FM64\n",
      "[ 7.0617  5.8033  5.6797  1.6611  0.722   2.2276 -1.4683  1.4746  3.4887]\n",
      "\n",
      "Method: WSS_GAM64\n",
      "[ 4.6595  5.8435  5.66    2.0062  0.9093  0.4179 -0.0542  2.6583  3.1954]\n",
      "\n",
      "Method: BetaShap (U)64\n",
      "[10.0383 12.6489 21.0797  1.6714 -0.1064 10.794   5.5487  3.3006  7.6744]\n",
      "\n",
      "Method: TMC64\n",
      "[8.6751 8.1645 4.9616 1.6388 0.0257 6.2091 0.0941 1.6969 4.2398]\n",
      "\n",
      "Method: ContextCite100\n",
      "[ 6.2975  5.5954  5.7493  0.6833  0.7491  1.4058 -1.1434  0.6064  4.7892]\n",
      "\n",
      "Method: WSS_FM100\n",
      "[ 7.4709  5.6914  5.5313  0.9292  1.6024  2.3775 -1.6037  0.7191  3.7047]\n",
      "\n",
      "Method: WSS_GAM100\n",
      "[ 6.1914  5.339   5.5478  1.2407  0.3826  1.4799 -1.3205  0.7397  4.5337]\n",
      "\n",
      "Method: BetaShap (U)100\n",
      "[ 9.5034 14.1564  7.1907  3.8051  0.5825 12.1794  2.4923  3.3006  8.956 ]\n",
      "\n",
      "Method: TMC100\n",
      "[ 7.7263  8.3901  3.4304  1.7979  0.886   5.34   -0.0225  1.6486  6.5103]\n",
      "\n",
      "Method: LOO\n",
      "[11.6427  0.5892  0.2462  1.6714  0.5825 -0.2894 -0.5642  0.194   1.2666]\n"
     ]
    }
   ],
   "source": [
    "print(\"     Approximate Scores\")\n",
    "print(\"============================\")\n",
    "for method, approx_scores in results_for_query.items():\n",
    "    if approx_scores is not None:\n",
    "        print(f\"\\nMethod: {method}\")\n",
    "        print(np.round(approx_scores, 4))\n",
    "accelerator_main.wait_for_everyone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
