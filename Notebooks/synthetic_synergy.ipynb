{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, rankdata\n",
    "from sklearn.metrics import ndcg_score\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import Accelerator\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from SHapRAG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../data/synthetic_data/20_synergy_hard_negatives.csv\",index_col=False, sep=\";\")\n",
    "# df= pd.read_csv(\"../data/complementary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.context[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "# \"The weather in Chorvoq is stormy today.\",\n",
    "\"Chorvoq is the capital of Narniya.\",\n",
    "# \"The sun is shining in Galaba today\",\n",
    "\"Nurik is the capital of Suvsambil.\",\n",
    "\"Narniya borders several countries including Suvsambil.\",\n",
    "\"The currency used in Narniya is the Euro.\",\n",
    "\"Narniya is the biggest country in the Olam\",\n",
    "# \"Chorvoq hosted the Summer Olympics in 1900 and 1924.\",\n",
    "\"The capital of Narniya is Chorvoq.\",\n",
    "# \"Suvsambil uses the Euro as well.\",\n",
    "\"It is cloudy in Nurik today.\"\n",
    "]\n",
    "query = \"What is the capital of the biggest country in the Olam?\"\n",
    "# Parameters\n",
    "NUM_RETRIEVED_DOCS = len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Script: Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Script: Preparing model with Accelerator...\n",
      "Main Script: Model prepared and set to eval.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "# Initialize Accelerator\n",
    "accelerator_main = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "# Load Model\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Loading model...\")\n",
    "# model_path = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "model_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# model_path = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "model_cpu = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model_cpu.config.pad_token_id = tokenizer.pad_token_id\n",
    "    if hasattr(model_cpu, 'generation_config') and model_cpu.generation_config is not None:\n",
    "        model_cpu.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Preparing model with Accelerator...\")\n",
    "prepared_model = accelerator_main.prepare(model_cpu)\n",
    "unwrapped_prepared_model = accelerator_main.unwrap_model(prepared_model)\n",
    "unwrapped_prepared_model.eval()\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Model prepared and set to eval.\")\n",
    "\n",
    "# Define utility cache\n",
    "\n",
    "accelerator_main.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions:   0%|          | 0/20 [00:00<?, ?it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question 1/20: What kind of energy does the facility hovering the planet Xy... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q0 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Electrical power.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx0_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 241.66it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:   5%|▌         | 1/20 [00:00<00:15,  1.25it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q0\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 2/20: What is the primary defense of the creatures populating the ... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q1 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'The primary defense of the creatures populating the Subterranean Caves is their unique abilities to protect themselves from predators.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx1_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 268.90it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  10%|█         | 2/20 [00:02<00:22,  1.27s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q1\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 3/20: What is the main function of the device recently discovered ... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q2 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Stabilize localized temporal distortions.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx2_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 309.74it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  15%|█▌        | 3/20 [00:03<00:18,  1.06s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q2\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 4/20: What is the composition of the natural wonder of planet Ntun... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q3 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'The 'Floating Islands of Aeridia' are primarily composed of Aeridium Ore.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx3_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 297.50it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  20%|██        | 4/20 [00:04<00:18,  1.13s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q3\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 5/20: What is the traditional weapon of the defenders of the Citad... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q4 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'The traditional weapon of the Sky-Guardians.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx4_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 352.55it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  25%|██▌       | 5/20 [00:05<00:15,  1.06s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q4\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 6/20: What kind of power source is used by the ancient constructs ... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q5 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Animus Cores, Geothermal Converters, and Starlight Capacitors.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx5_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 268.29it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  30%|███       | 6/20 [00:06<00:15,  1.12s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q5\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 7/20: What is the primary ingredient of the most famous healing po... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q6 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Finely ground powder from Glow-Moss.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx6_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 328.42it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  35%|███▌      | 7/20 [00:07<00:13,  1.04s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q6\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 8/20: What defensive ability is possessed by the strongest creatur... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q7 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Instantaneous growth of razor-sharp crystalline thorns.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx7_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 305.32it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  40%|████      | 8/20 [00:08<00:12,  1.02s/it]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q7\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 9/20: What is the energy source of the massive orbital platform or... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q8 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'A miniature black hole.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx8_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 320.76it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  45%|████▌     | 9/20 [00:09<00:10,  1.10it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q8\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 10/20: What is the population of the capital of the biggest country... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q9 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Over 300 million people.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx9_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 316.43it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  50%|█████     | 10/20 [00:09<00:08,  1.18it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q9\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 11/20: What's the weather like in the capital of Zhykara?... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q10 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Ktharr City is experiencing a snow storm.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx10_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 311.90it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  55%|█████▌    | 11/20 [00:10<00:07,  1.17it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q10\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 12/20: What's the value of the element obtained by mixing Aethelite... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q11 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Nitros.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx11_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 299.07it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  60%|██████    | 12/20 [00:11<00:06,  1.26it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q11\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 13/20: What's the side effect of mixing Gravitium and Solara?... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q12 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Creating Umbradium.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx12_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 317.05it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  65%|██████▌   | 13/20 [00:12<00:05,  1.30it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q12\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 14/20: What is the radius of the largest planet in the K'tharr Syst... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q13 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: '120,000 kilometers.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx13_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 305.37it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  70%|███████   | 14/20 [00:12<00:04,  1.35it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q13\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 15/20: What is the population of the smallest planet in the Lumina ... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q14 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: '1.5 million.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx14_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 304.89it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  75%|███████▌  | 15/20 [00:13<00:03,  1.34it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q14\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 16/20: What is the title of the latest film starring the highest-pa... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q15 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: ''Echoes of the Nebulae'.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx15_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 305.63it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  80%|████████  | 16/20 [00:14<00:03,  1.26it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q15\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 17/20: What is the salary of the most popular actor on the planet A... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q16 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: '50 million Credits per major project.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx16_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 285.14it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  85%|████████▌ | 17/20 [00:15<00:02,  1.21it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q16\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 18/20: What is the title of the first album by the most popular Chr... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q17 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'Temporal Drift.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx17_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 272.48it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  90%|█████████ | 18/20 [00:16<00:01,  1.25it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q17\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 19/20: What is the total number of plays for the most critically ap... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q18 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: '450 million.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx18_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 286.91it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions:  95%|█████████▌| 19/20 [00:16<00:00,  1.31it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q18\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "--- Question 20/20: What is the effect of drinking water from the sacred spring ... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q19 (n=10 docs)...\n",
      "Generating target response based on full context...\n",
      "Target response: 'The water from the Font of Resonance amplifies the mental abilities of those who drink it.'\n",
      "Successfully loaded utilities from ../Experiment_data/synergy/utilities_q_idx19_n10.pkl. Found 1024 entries.\n",
      "Broadcasted loaded utilities to all processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pairwise Interactions (Matrix): 100%|██████████| 45/45 [00:00<00:00, 267.17it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1389: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Processing Questions: 100%|██████████| 20/20 [00:18<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to empty CUDA cache on rank 0 after Q19\n",
      "CUDA cache empty attempt complete on rank 0.\n",
      "\n",
      "\n",
      "--- Average Correlation Metrics Across All Questions ---\n",
      "                Avg_Pearson  Avg_Kendall  Num_Valid_Queries\n",
      "Method                                                     \n",
      "ExactInter           1.0000       1.0000                 20\n",
      "ExactLinear          1.0000       1.0000                 20\n",
      "WSS_FM100            0.9829       0.7280                 20\n",
      "ContextCite100       0.9743       0.6714                 20\n",
      "TMC100               0.9457       0.6372                 20\n",
      "BetaShap100          0.9272       0.6480                 20\n",
      "LOO                  0.8690       0.5029                 20\n",
      "Script finished.\n",
      "Rank 0 (Local Main): Distributed environment not initialized or not available, skipping destroy_process_group.\n",
      "Script fully exited.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_questions_to_run=len(df.question)\n",
    "# num_questions_to_run=1\n",
    "all_metrics_data = []\n",
    "all_results=[]\n",
    "M=[]\n",
    "Fs=[]\n",
    "pairs=[]\n",
    "mse_inters=[]\n",
    "mse_lins=[]\n",
    "mse_fms=[]\n",
    "for i in tqdm(range(num_questions_to_run), desc=\"Processing Questions\", disable=not accelerator_main.is_main_process):\n",
    "    query = df.question[i]\n",
    "    if accelerator_main.is_main_process:\n",
    "        print(f\"\\n--- Question {i+1}/{num_questions_to_run}: {query[:60]}... ---\")\n",
    "\n",
    "    docs=ast.literal_eval(df.context[i])\n",
    "\n",
    "    utility_cache_base_dir = \"../Experiment_data/synergy\"\n",
    "    utility_cache_filename = f\"utilities_q_idx{i}_n{len(docs)}.pkl\" # More robust naming\n",
    "    current_utility_path = os.path.join(utility_cache_base_dir, utility_cache_filename)\n",
    "    \n",
    "    if accelerator_main.is_main_process: # Only main process creates directories\n",
    "        os.makedirs(os.path.dirname(current_utility_path), exist_ok=True)\n",
    "        print(f\"  Instantiating ShapleyExperimentHarness for Q{i} (n={len(docs)} docs)...\")\n",
    "    \n",
    "    # Initialize Harness\n",
    "    harness = ShapleyExperimentHarness(\n",
    "        items=docs,\n",
    "        query=query,\n",
    "        prepared_model_for_harness=prepared_model,\n",
    "        tokenizer_for_harness=tokenizer,\n",
    "        accelerator_for_harness=accelerator_main,\n",
    "        verbose=True,\n",
    "        utility_path=current_utility_path\n",
    "    )\n",
    "    # Compute metrics\n",
    "    results_for_query = {}\n",
    "    M.append(harness.compute_shapley_interaction_index_pairs_matrix())\n",
    "    if accelerator_main.is_main_process:\n",
    "\n",
    "        results_for_query[\"ExactLinear\"], mse_lin = harness.compute_exact_linear_shap()\n",
    "        results_for_query[\"ExactInter\"], pair, mse_inter = harness.compute_exact_inter_shap()\n",
    "        pairs.append(pair)\n",
    "        mse_lins.append(mse_lin)\n",
    "        mse_inters.append(mse_inter)\n",
    "        m_samples_map = {\"L\": 100} \n",
    "        T_iterations_map = { \"L\":20} \n",
    "\n",
    "        for size_key, num_s in m_samples_map.items():\n",
    "            if 2**len(docs) < num_s and size_key != \"L\":\n",
    "                actual_samples = max(1, 2**len(docs)-1 if 2**len(docs)>0 else 1)\n",
    "            else:\n",
    "                actual_samples = num_s\n",
    "\n",
    "            if actual_samples > 0: \n",
    "                results_for_query[f\"ContextCite{actual_samples}\"] = harness.compute_contextcite_weights(num_samples=actual_samples, seed=SEED)\n",
    "                results_for_query[f\"WSS_FM{actual_samples}\"], F, mse_fm = harness.compute_wss(num_samples=actual_samples, seed=SEED, distil=None, sampling=\"kernelshap\",sur_type=\"fm\", util='pure-surrogate', pairchecking=False)\n",
    "                Fs.append(F)\n",
    "                mse_fms.append(mse_fm)\n",
    "                results_for_query[f\"BetaShap{actual_samples}\"] = harness.compute_beta_shap(num_iterations_max=T_iterations_map[size_key], beta_a=4, beta_b=4, max_unique_lookups=actual_samples, seed=SEED)\n",
    "                results_for_query[f\"TMC{actual_samples}\"] = harness.compute_tmc_shap(num_iterations_max=T_iterations_map[size_key], performance_tolerance=0.001, max_unique_lookups=actual_samples, seed=SEED)\n",
    "\n",
    "        results_for_query[\"LOO\"] = harness.compute_loo()\n",
    "\n",
    "        exact_scores = results_for_query.get(\"ExactInter\")\n",
    "        all_results.append(results_for_query)\n",
    "        if exact_scores is not None:\n",
    "            positive_exact_score = np.clip(exact_scores, a_min=0.0, a_max=None) # FOR NDGC SCORE COMPUTATION\n",
    "            for method, approx_scores in results_for_query.items():\n",
    "                if method != \"Exact\" and approx_scores is not None:\n",
    "                    if len(approx_scores) == len(exact_scores):\n",
    "                        if np.all(exact_scores == exact_scores[0]) or np.all(approx_scores == approx_scores[0]):\n",
    "                            pearson_c = 1.0 if np.allclose(exact_scores, approx_scores) else 0.0\n",
    "                            spearman_c = 1.0 if np.allclose(exact_scores, approx_scores) else 0.0\n",
    "                        else:\n",
    "                            pearson_c, _ = pearsonr(exact_scores, approx_scores)\n",
    "                            exact_ranks = rankdata(-np.array(exact_scores), method=\"average\") # rank scores with the smallest =1 and when there is a tie assign the average rank\n",
    "                            approx_ranks = rankdata(-np.array(approx_scores), method = \"average\")\n",
    "                            kendall_c, _ = kendalltau(exact_ranks, approx_ranks) # return tau and pval (if pval is < 0.005 we can say that correlation is statistically significant) \n",
    "                        \n",
    "                        all_metrics_data.append({\n",
    "                            \"Question_Index\": i, \"Query\": query, \"Method\": method,\n",
    "                            \"Pearson\": pearson_c, \"KendallTau\" : kendall_c,\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"    Score length mismatch for method {method} (Exact: {len(exact_scores)}, Approx: {len(approx_scores)}). Skipping metrics.\")\n",
    "        else:\n",
    "            print(f\"    Skipping metric calculation for Q{i} as Exact Shapley was not computed or failed.\")\n",
    "    \n",
    "    accelerator_main.wait_for_everyone() \n",
    "   \n",
    "    if torch.cuda.is_available():\n",
    "        if accelerator_main.is_main_process: # Print from one process\n",
    "            print(f\"Attempting to empty CUDA cache on rank {accelerator_main.process_index} after Q{i}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        if accelerator_main.is_main_process:\n",
    "            print(f\"CUDA cache empty attempt complete on rank {accelerator_main.process_index}.\")\n",
    "    accelerator_main.wait_for_everyone()\n",
    "\n",
    "\n",
    "if accelerator_main.is_main_process:\n",
    "    if all_metrics_data:\n",
    "        metrics_df_all_questions = pd.DataFrame(all_metrics_data)\n",
    "        print(\"\\n\\n--- Average Correlation Metrics Across All Questions ---\")\n",
    "        average_metrics = metrics_df_all_questions.groupby(\"Method\").agg(\n",
    "            Avg_Pearson=(\"Pearson\", \"mean\"),\n",
    "            Avg_Kendall =(\"KendallTau\", \"mean\"),\n",
    "            Num_Valid_Queries=(\"Query\", \"nunique\")\n",
    "        ).sort_values(by=\"Avg_Pearson\", ascending=False)\n",
    "        \n",
    "        print(average_metrics.round(4))\n",
    "    else:\n",
    "        print(\"\\nNo metrics were collected. This might be due to all calculations failing or only non-main processes running sections.\")\n",
    "\n",
    "# Final synchronization before script ends\n",
    "accelerator_main.wait_for_everyone()\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Script finished.\")\n",
    "\n",
    "if torch.distributed.is_available() and torch.distributed.is_initialized():\n",
    "    if accelerator_main.is_local_main_process:\n",
    "        print(f\"Rank {accelerator_main.process_index} (Local Main): Manually destroying process group...\")\n",
    "    torch.distributed.destroy_process_group()\n",
    "    if accelerator_main.is_local_main_process:\n",
    "        print(f\"Rank {accelerator_main.process_index} (Local Main): Process group destroyed.\")\n",
    "else:\n",
    "    if accelerator_main.is_local_main_process:\n",
    "        print(f\"Rank {accelerator_main.process_index} (Local Main): Distributed environment not initialized or not available, skipping destroy_process_group.\")\n",
    "\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Script fully exited.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction: [0.09774896487687629, 0.08501734797637668, 0.019761560652927196, 0.0013347903692996028, 0.06594404028146503, 0.011158172847565583, 0.4172564780502045, 0.017130628046105052, 0.0096394961241482, 0.16791229510289846, 0.25242411255181035, 0.003831703077902289, 0.013714988396998282, 0.1776722058603319, 0.36979628095176587, 0.05542755963874956, 0.2263621876018738, 0.6102293614713568, 0.3508369116190768, 0.057492438415899946],\n",
      " Linear: [0.18623424128922017, 0.256493055526992, 0.03287140214429542, 0.003055569215165882, 0.12238553221081654, 0.023090882675048083, 2.1687463838740237, 0.06172822208809088, 0.06581568918490696, 1.15222384080821, 1.4507206752577928, 0.009518625205963398, 0.0575383762267966, 0.763112184921872, 1.606143661656533, 0.5935353140628266, 1.3195736251198666, 2.837954017985678, 1.6520974264059336, 0.2096100033402582],\n",
      " FM: [0.07447952886097514, 0.07027152408649431, 0.011676865132733605, 0.0011816209018718307, 0.04522814841564803, 0.007110059422978513, 0.27927141761807295, 0.012019665825905414, 0.004701988263133106, 0.08060908638990945, 0.207261706659302, 0.0013344114577598706, 0.009197837157056625, 0.11683480476207517, 0.24399152535422086, 0.03792544688825181, 0.1921053309680017, 0.2917719382438186, 0.25614226024469017, 0.041140617348598536]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Interaction: {mse_inters},\\n Linear: {mse_lins},\\n FM: {mse_fms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction: 3.0106915239136316,\n",
      " Linear: 14.57244872920029,\n",
      " FM: 1.9842557840014978\n"
     ]
    }
   ],
   "source": [
    "print(f\"Interaction: {sum(mse_inters)},\\n Linear: {sum(mse_lins)},\\n FM: {sum(mse_fms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harness.compute_exhaustive_top_k(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate metrics\n",
    "all_metrics_data = []\n",
    "exact_scores = results_for_query.get(\"Exact\")\n",
    "if exact_scores is not None:\n",
    "    positive_exact_score = np.clip(exact_scores, a_min=0.0, a_max=None)\n",
    "    for method, approx_scores in results_for_query.items():\n",
    "        if method != \"Exact\" and approx_scores is not None and len(approx_scores) == len(exact_scores):\n",
    "            if np.all(exact_scores == exact_scores[0]) or np.all(approx_scores == approx_scores[0]):\n",
    "                pearson_c = spearman_c = 1.0 if np.allclose(exact_scores, approx_scores) else 0.0\n",
    "            else:\n",
    "                pearson_c, _ = pearsonr(exact_scores, approx_scores)\n",
    "                spearman_c, _ = spearmanr(exact_scores, approx_scores)\n",
    "                exact_ranks = rankdata(-np.array(exact_scores), method=\"average\")\n",
    "                approx_ranks = rankdata(-np.array(approx_scores), method=\"average\")\n",
    "                kendall_c, _ = kendalltau(exact_ranks, approx_ranks)\n",
    "            ndgc_scoring = ndcg_score([positive_exact_score], [approx_scores], k=3)\n",
    "\n",
    "            all_metrics_data.append({\n",
    "                    \"Method\": method,\n",
    "                \"Pearson\": pearson_c, \"Spearman\": spearman_c, \"NDCG\": ndgc_scoring, \"KendallTau\": kendall_c\n",
    "            })\n",
    "            all_metrics_data.sort(key=lambda x: x[\"Pearson\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "method_scores = {}\n",
    "\n",
    "for result in all_results:\n",
    "    for method, scores in result.items():\n",
    "        if scores is not None:\n",
    "            method_scores[method] = np.round(scores, 4)\n",
    "\n",
    "for method, scores in method_scores.items():\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(scores)), scores, color='skyblue')\n",
    "    plt.title(f\"Approximate Scores: {method}\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.xticks(range(len(scores)))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.context[19]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
