{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, rankdata\n",
    "from sklearn.metrics import ndcg_score\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import Accelerator\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from SHapRAG import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"../data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Script: Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Script: Preparing model with Accelerator...\n",
      "Main Script: Model prepared and set to eval.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "# Initialize Accelerator\n",
    "accelerator_main = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "# Load Model\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Loading model...\")\n",
    "# model_path = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# model_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "model_path = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "model_cpu = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model_cpu.config.pad_token_id = tokenizer.pad_token_id\n",
    "    if hasattr(model_cpu, 'generation_config') and model_cpu.generation_config is not None:\n",
    "        model_cpu.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Preparing model with Accelerator...\")\n",
    "prepared_model = accelerator_main.prepare(model_cpu)\n",
    "unwrapped_prepared_model = accelerator_main.unwrap_model(prepared_model)\n",
    "unwrapped_prepared_model.eval()\n",
    "if accelerator_main.is_main_process:\n",
    "    print(\"Main Script: Model prepared and set to eval.\")\n",
    "\n",
    "# Define utility cache\n",
    "\n",
    "accelerator_main.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions:   0%|          | 0/2 [00:00<?, ?it/s]/transformers/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/transformers/src/transformers/generation/configuration_utils.py:658: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question 1/2: Are director of film Move (1970 Film) and director of film M... ---\n",
      "  Instantiating ShapleyExperimentHarness for Q0 (n=10 docs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|██████████| 3/3 [00:00<00:00, 12029.55it/s]\n",
      "Processing Questions:   0%|          | 0/2 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Out of bounds on buffer access (axis 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     actual_samples \u001b[38;5;241m=\u001b[39m num_s\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# results_for_query[f\"ContextCite{actual_samples}\"] = harness.compute_contextcite_weights(num_samples=actual_samples, seed=SEED)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     results_for_query[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWSS_FM\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], F, modelfm \u001b[38;5;241m=\u001b[39m \u001b[43mharness\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_wss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactual_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkernelshap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msur_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     results_for_query[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBetaShap\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m harness\u001b[38;5;241m.\u001b[39mcompute_beta_shap(num_iterations_max\u001b[38;5;241m=\u001b[39mT_iterations_map[size_key], beta_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, beta_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_unique_lookups\u001b[38;5;241m=\u001b[39mactual_samples, seed\u001b[38;5;241m=\u001b[39mSEED)\n\u001b[1;32m     44\u001b[0m     results_for_query[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTMC\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m harness\u001b[38;5;241m.\u001b[39mcompute_tmc_shap(num_iterations_max\u001b[38;5;241m=\u001b[39mT_iterations_map[size_key], performance_tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, max_unique_lookups\u001b[38;5;241m=\u001b[39mactual_samples, seed\u001b[38;5;241m=\u001b[39mSEED)\n",
      "File \u001b[0;32m~/LLMX/SHapRAG/rag_shap.py:376\u001b[0m, in \u001b[0;36mContextAttribution.compute_wss\u001b[0;34m(self, num_samples, seed, sampling, sur_type)\u001b[0m\n\u001b[1;32m    374\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(s_tuple)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    375\u001b[0m     x_sparse \u001b[38;5;241m=\u001b[39m csr_matrix(x)\n\u001b[0;32m--> 376\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43mfm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sparse\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    377\u001b[0m     utilities[s_tuple] \u001b[38;5;241m=\u001b[39m u\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# 4) Compute exact Shapley using FM utilities\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastFM/base.py:102\u001b[0m, in \u001b[0;36mFactorizationMachine.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix_csc(X_test)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mffm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffm_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw0_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mfastFM/ffm.pyx:82\u001b[0m, in \u001b[0;36mffm.ffm_predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfastFM/ffm.pyx:39\u001b[0m, in \u001b[0;36mffm.CsMatrix\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Out of bounds on buffer access (axis 0)"
     ]
    }
   ],
   "source": [
    "# num_questions_to_run=len(df.question)\n",
    "num_questions_to_run=2\n",
    "all_metrics_data = []\n",
    "all_results=[]\n",
    "for i in tqdm(range(num_questions_to_run), desc=\"Processing Questions\", disable=not accelerator_main.is_main_process):\n",
    "    query = df.question[i]\n",
    "    if accelerator_main.is_main_process:\n",
    "        print(f\"\\n--- Question {i+1}/{num_questions_to_run}: {query[:60]}... ---\")\n",
    "\n",
    "    docs=[\"/n\".join(i[1]) for i in ast.literal_eval(df.context[i])]\n",
    "\n",
    "    utility_cache_base_dir = \"../Experiment_data/2wiki\"\n",
    "    utility_cache_filename = f\"utilities_q_idx{i}_n{len(docs)}.pkl\" # More robust naming\n",
    "    current_utility_path = os.path.join(utility_cache_base_dir, utility_cache_filename)\n",
    "    \n",
    "    if accelerator_main.is_main_process: # Only main process creates directories\n",
    "        os.makedirs(os.path.dirname(current_utility_path), exist_ok=True)\n",
    "        print(f\"  Instantiating ShapleyExperimentHarness for Q{i} (n={len(docs)} docs)...\")\n",
    "    \n",
    "    # Initialize Harness\n",
    "    harness = ContextAttribution(\n",
    "        items=docs,\n",
    "        query=query,\n",
    "        prepared_model_for_harness=prepared_model,\n",
    "        tokenizer_for_harness=tokenizer,\n",
    "        accelerator_for_harness=accelerator_main,\n",
    "    )\n",
    "    # Compute metrics\n",
    "    results_for_query = {}\n",
    "    if accelerator_main.is_main_process:\n",
    "        m_samples_map = {\"L\": 100} \n",
    "        T_iterations_map = {\"L\":40} \n",
    "\n",
    "        for size_key, num_s in m_samples_map.items():\n",
    "            if 2**len(docs) < num_s and size_key != \"L\":\n",
    "                actual_samples = max(1, 2**len(docs)-1 if 2**len(docs)>0 else 1)\n",
    "            else:\n",
    "                actual_samples = num_s\n",
    "\n",
    "            if actual_samples > 0: \n",
    "                # results_for_query[f\"ContextCite{actual_samples}\"] = harness.compute_contextcite_weights(num_samples=actual_samples, seed=SEED)\n",
    "                results_for_query[f\"FM_Shap{actual_samples}\"], results_for_query[f\"FM_Weights{actual_samples}\"], F, modelfm = harness.compute_wss(num_samples=actual_samples, seed=SEED, sampling=\"kernelshap\",sur_type=\"fm\")\n",
    "                results_for_query[f\"BetaShap{actual_samples}\"] = harness.compute_beta_shap(num_iterations_max=T_iterations_map[size_key], beta_a=16, beta_b=1, max_unique_lookups=actual_samples, seed=SEED)\n",
    "                results_for_query[f\"TMC{actual_samples}\"] = harness.compute_tmc_shap(num_iterations_max=T_iterations_map[size_key], performance_tolerance=0.001, max_unique_lookups=actual_samples, seed=SEED)\n",
    "\n",
    "        results_for_query[\"LOO\"] = harness.compute_loo()\n",
    "        results_for_query[\"ARC-JSD\"] = harness.compute_arc_jsd()\n",
    "\n",
    "        all_results.append(results_for_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ContextCite: {mse_ccs},\\n FM: {mse_fms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ContextCite: {sum(mse_ccs)},\\n FM: {sum(mse_fms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.context[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "method_scores = {}\n",
    "\n",
    "for result in all_results:\n",
    "    for method, scores in result.items():\n",
    "        if scores is not None:\n",
    "            method_scores[method] = np.round(scores, 4)\n",
    "\n",
    "for method, scores in method_scores.items():\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(scores)), scores, color='skyblue')\n",
    "    plt.title(f\"Approximate Scores: {method}\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.xticks(range(len(scores)))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
