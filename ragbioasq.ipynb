{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs.aau.dk/em63by/anaconda3/envs/llmx/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer\n",
    "tqdm.pandas()\n",
    "\n",
    "splits = {'train': 'question-answer-passages/train-00000-of-00001.parquet', 'test': 'question-answer-passages/test-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/enelpol/rag-mini-bioasq/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"hf://datasets/enelpol/rag-mini-bioasq/text-corpus/test-00000-of-00001.parquet\")\n",
    "df1['passage']=df1['passage'].str.replace(r'[\\n]', ' ', regex=True)\n",
    "df['question']=df['question'].str.replace(r'[\\n]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_embs(qtext, model=\"nomic\"):\n",
    "    if model==\"nomic\":\n",
    "    \n",
    "        data = {\n",
    "            \"model\": \"nomic-embed-text\",\n",
    "            \"prompt\": qtext\n",
    "        }\n",
    "        return np.array(requests.post('http://localhost:11434/api/embeddings', json=data).json()['embedding'])\n",
    "    else:\n",
    "        return SentenceTransformer(\"abhinand/MedEmbed-large-v0.1\").encode([qtext], convert_to_numpy=True)\n",
    "    \n",
    "# df1['embedding'] = df1['passage'].progress_apply(lambda x: gen_embs(x, model='medemb'))\n",
    "\n",
    "# # Save the embeddings to a pickle file\n",
    "# with open('embed_bioasq_medemb.pkl', 'wb') as f:\n",
    "#     pickle.dump(df1['embedding'].tolist(), f)\n",
    "# print(\"Embeddings saved to embed_bioasq_medemb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/embed_bioasq_medemb.pkl\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings):\n",
    "    return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "embeddings = normalize_embeddings(embeddings)\n",
    "\n",
    "def index_documents(method=\"faiss\", index_name=\"recipes_nomic\", es_host=\"http://localhost:9200\"):\n",
    "    if method == \"faiss\":\n",
    "        dimension = embeddings.shape[1]\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "        index.add(embeddings)\n",
    "        faiss.write_index(index, \"data/bioasq_nomic_faiss.index\")\n",
    "        print(\"FAISS index saved.\")\n",
    "        return index\n",
    "    elif method == \"elasticsearch\":\n",
    "        es = Elasticsearch(es_host)\n",
    "        mapping = {\"mappings\": {\"properties\": {\"text\": {\"type\": \"text\"}, \"vector\": {\"type\": \"dense_vector\", \"dims\": embeddings.shape[1]}}}}\n",
    "        es.indices.create(index=index_name, body=mapping, ignore=400)\n",
    "        for i, (text, vector) in enumerate(zip(documents, embeddings)):\n",
    "            es.index(index=index_name, id=i, body={\"text\": text, \"vector\": vector.tolist()})\n",
    "        print(\"Elasticsearch index created.\")\n",
    "        return es\n",
    "# index_documents(method=\"faiss\", index_name=\"bioasq_nomic_faiss\", es_host=\"http://localhost:9200\")\n",
    "faiss_index = faiss.read_index(\"data/medemb_bioasq_faiss.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query, k=5):\n",
    "    query_embedding = gen_embs(query, model=\"medemb\")\n",
    "    query_embedding = normalize_embeddings(query_embedding.reshape(1, -1))\n",
    "    scores, indices = faiss_index.search(query_embedding, k)\n",
    "    return [df1['passage'][i] for i in indices[0]], scores\n",
    "\n",
    "### 3️⃣ Query RAG Pipeline ###\n",
    "def query_rag(query, retrieved_docs=None):\n",
    "    \"\"\"Query the Ollama API with a prompt based on provided documents.\"\"\"\n",
    "    if retrieved_docs:\n",
    "        retrieved_text = \"\\n\".join(retrieved_docs)\n",
    "        prompt = f\"Using only the following context, answer the question. \\nContext:{retrieved_text} \\n Be concise and short. If you can not find a relevant information from the provided, then just answer -I do not have this information.\\n Question: {query}. Answer:\"\n",
    "    else:\n",
    "        prompt= f'You are an expert in medical domain. Given the question provide a relevant answer. Question: {query}. Answer:'\n",
    "    HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\"model\": \"llama3.3\", \"prompt\": prompt, 'stream': False}\n",
    "\n",
    "    response = requests.post(url, headers=HEADERS, json=data)\n",
    "\n",
    "    return response.json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='List the common retinal diseases associated with circRNA and relate to tumorigenesis?'\n",
    "docs, scores=retrieve_documents(query=query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43578189611434937\tCircular RNAs (circRNAs) are a novel class of endogenous non-coding RNAs  produced by back-splicing. They are found to be expressed in eukaryotic cells  and play certain roles in various cellular functions, including fibrosis, cel\n",
      "\n",
      "0.4444296360015869\tRetinal neovascularization is a complication which caused human vision loss  severely. It has been shown that circular RNAs (circRNAs) play essential roles  in gene regulation. However, circRNA expression profile and the underlyin\n",
      "\n",
      "0.4829050302505493\tA newly rediscovered subclass of noncoding RNAs, circular RNAs (circRNAs), is  produced by a back-splicing mechanism with a covalently closed loop structure.  They not only serve as the sponge for microRNAs (miRNAs) and proteins b\n",
      "\n",
      "0.5035773515701294\tIn diabetic patients, diabetic retinopathy (DR) is the leading cause of  blindness and seriously affects the quality of life. However, current treatment  methods of DR are not satisfactory. Advances have been made in understanding\n",
      "\n",
      "0.5076253414154053\tCircular RNAs (circRNAs) are being hailed as a newly rediscovered class of  covalently closed transcripts that are produced via alternative, noncanonical  pre-mRNA back-splicing events. These single-stranded RNA molecules have bee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(scores[0], docs):\n",
    "    print(f\"{a}\\t{b[:230]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37541    31171902\n",
       " Name: id, dtype: int64,\n",
       " 37864    31692917\n",
       " Name: id, dtype: int64,\n",
       " 38997    33015046\n",
       " Name: id, dtype: int64,\n",
       " 38574    32519377\n",
       " Name: id, dtype: int64,\n",
       " 39461    33761053\n",
       " Name: id, dtype: int64]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df1[df1['passage']==i]['id'] for i in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=query_rag(query=query, retrieved_docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=query_rag(query=query, retrieved_docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, here are some retinal diseases associated with circRNA:\n",
      "\n",
      "1. Diabetic retinopathy\n",
      "2. Retinoblastoma (related to tumorigenesis)\n",
      "3. Retinal neovascularization \n",
      "4. Proliferative vitreoretinopathy \n",
      "\n",
      "Note: The exact relationship between these diseases and tumorigenesis is not fully explained in the provided context, except for retinoblastoma which is directly related to tumorigenesis.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(subset, full_set_embedding):\n",
    "    \"\"\"\n",
    "    Cost function: Cosine similarity between the LLM's response for the subset and the full set.\n",
    "    \"\"\"\n",
    "    if not subset:\n",
    "        return 0.0  # Empty subset has no contribution\n",
    "    \n",
    "    # Query the LLM with the subset\n",
    "    response = query_rag(query, subset)\n",
    "    \n",
    "    # Generate and normalize embeddings for the subset's response\n",
    "    subset_embedding = normalize_embeddings(gen_embs(response, model='medemb').reshape(1, -1))\n",
    "    \n",
    "    # Compute cosine similarity with the full set's embedding\n",
    "    return cosine_similarity(subset_embedding, full_set_embedding)\n",
    "\n",
    "def shapley_values(S):\n",
    "    \"\"\"\n",
    "    Compute Shapley values for a set of textual queries S.\n",
    "    \"\"\"\n",
    "    S = list(S)\n",
    "    n = len(S)\n",
    "    \n",
    "    # Query the LLM with the full set to get the reference embedding\n",
    "    full_set_response = query_rag(query, S)\n",
    "    full_set_embedding = normalize_embeddings(gen_embs(full_set_response, model='medemb').reshape(1, -1))\n",
    "    \n",
    "    # Precompute the cost for all subsets\n",
    "    F_cache = {}\n",
    "    for bitmask in tqdm(range(0, 1 << n), desc=\"Calculating cosine to full response\"):\n",
    "        subset = [S[i] for i in range(n) if (bitmask & (1 << i))]\n",
    "        if len(subset)==n:\n",
    "            F_cache[bitmask] = 1\n",
    "        else:\n",
    "            F_cache[bitmask] = F(subset, full_set_embedding)\n",
    "    \n",
    "    # Initialize Shapley values\n",
    "    # shap = {element: 0.0 for element in S}\n",
    "    shap = np.zeros(len(S))\n",
    "    \n",
    "    # Calculate contributions for each subset\n",
    "    for bitmask in tqdm(range(0, 1 << n), desc=\"Calculating shap\"):\n",
    "        subset_size = bin(bitmask).count('1')\n",
    "        if subset_size == 0:\n",
    "            continue  # Skip empty subsets\n",
    "        \n",
    "        for i in range(n):\n",
    "            if not (bitmask & (1 << i)):\n",
    "                continue  # Skip subsets without the current element\n",
    "            \n",
    "            # Compute subset without the current element\n",
    "            subset_without_i = bitmask ^ (1 << i)\n",
    "            \n",
    "            # Compute Shapley weight\n",
    "            k = bin(subset_without_i).count('1')\n",
    "            weight = (math.factorial(k) * math.factorial(n - k - 1)) / math.factorial(n)\n",
    "            \n",
    "            # Compute marginal contribution\n",
    "            marginal = F_cache[bitmask] - F_cache[subset_without_i]\n",
    "            shap[i] += marginal * weight\n",
    "    \n",
    "    return shap\n",
    "\n",
    "def ragshap(values, retrival_type='max_shap'):\n",
    "    if retrival_type=='max_shap':\n",
    "        new_query=docs[values.argmax()]\n",
    "    else:\n",
    "        new_query=query_rag(query=query, retrieved_docs=docs[values.argmax()])\n",
    "    new_docs, new_scores=retrieve_documents(query=new_query, k=5)\n",
    "    return query_rag(query=query, retrieved_docs=docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating cosine to full response: 100%|██████████| 32/32 [06:13<00:00, 11.66s/it]\n",
      "Calculating shap:   0%|          | 0/32 [00:00<?, ?it/s]/tmp/ipykernel_2643665/3124159742.py:60: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  shap[i] += marginal * weight\n",
      "Calculating shap: 100%|██████████| 32/32 [00:00<00:00, 24105.20it/s]\n"
     ]
    }
   ],
   "source": [
    "shap=shapley_values(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, here are some common retinal diseases associated with circRNA:\\n\\n1. Diabetic retinopathy (DR)\\n2. Retinoblastoma\\n3. Retinal neovascularization \\n4. Proliferative vitreoretinopathy \\n\\nThese circRNAs may play a role in tumorigenesis, particularly in retinoblastoma, which is a type of eye cancer.'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragshap(shap, retrival_type='max_shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
